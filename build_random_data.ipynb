{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBuild /mnt/ebs/code/forked-context-aware-decoding/eval/apps_tmp/random_2_-1.jsonl with apps data.\\nWhere the with-context prompt would be containing random training examples\\nwith their ground-truth code.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build /mnt/ebs/code/forked-context-aware-decoding/eval/apps_tmp/random_2_-1.jsonl with apps data.\n",
    "Where the with-context prompt would be containing random training examples\n",
    "with their ground-truth code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, data_type):\n",
    "    data_path_1 = f\"/mnt/ebs/code/hallucination-mitigation/data/{dataset}/{data_type}_samples_1.jsonl\"\n",
    "    data_path_2 = f\"/mnt/ebs/code/hallucination-mitigation/data/{dataset}/{data_type}_samples_2.jsonl\"\n",
    "    df_1 = pd.read_json(data_path_1, lines=True)\n",
    "    df_2 = pd.read_json(data_path_2, lines=True)\n",
    "    # combine the two dataframes\n",
    "    df = pd.concat([df_1, df_2], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(\"apps\", \"train\")\n",
    "test_df = load_data(\"apps\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dsc_context(problem):\n",
    "    prompt = \"\\nQUESTION:\\n\"\n",
    "    prompt += problem[\"question\"]\n",
    "    fn_name = problem[\"fn_name\"]\n",
    "\n",
    "    if not fn_name:\n",
    "        call_format = \"\\nPlease write your code using Standard Input, i.e. input() and print().\"\n",
    "        prompt += call_format\n",
    "    else:\n",
    "        call_format = \"\\Please write your code using Call-Based format.\"\n",
    "        prompt += call_format\n",
    "\n",
    "    system_prompt = \"You are an expert code developer with years of experience.\"\n",
    "    user_prompt = f'''As an expert code developer with years of experience, please provide the python code based on the question. Ensure the code is enclosed within triple backticks (```) to mark the start and end of the code block.\\n{prompt}'''\n",
    "\n",
    "    prompt = f'''You are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n",
    "### Instruction:\n",
    "{system_prompt}\n",
    "\n",
    "{user_prompt}\n",
    "### Response:\n",
    "'''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dsc_context_with_few_shot(test_problem, train_problems):\n",
    "    prompt = \"\\nQUESTION:\\n\"\n",
    "    prompt += test_problem[\"question\"]\n",
    "    fn_name = test_problem[\"fn_name\"]\n",
    "\n",
    "    if not fn_name:\n",
    "        call_format = \"\\nPlease write your code using Standard Input, i.e. input() and print().\"\n",
    "        prompt += call_format\n",
    "    else:\n",
    "        call_format = \"\\Please write your code using Call-Based format.\"\n",
    "        prompt += call_format\n",
    "\n",
    "    # add few-shot examples\n",
    "    example_prompt = \"\\n\\nEXAMPLES:\\n\"\n",
    "    for i in range(len(train_problems)):\n",
    "        train_problem = train_problems.iloc[i]\n",
    "        # print(train_problem.keys())\n",
    "        example_prompt += f\"\\nExample {i+1}:\\n\"\n",
    "        example_prompt += train_problem[\"question\"]\n",
    "        example_prompt += \"\\n\\nAnswer:\\n\"\n",
    "        # print(type(train_problem[\"solutions\"]))\n",
    "        example_prompt += train_problem[\"solutions\"][0]\n",
    "\n",
    "    system_prompt = \"You are an expert code developer with years of experience. You have been provided with a few examples to help you answer the question.\"\n",
    "    user_prompt = f'''As an expert code developer with years of experience, please provide the python code based on the question. You may consult the following example coding questions and their answers to provide the code. Ensure the code is enclosed within triple backticks (```) to mark the start and end of the code block.\\n{example_prompt}\\n{prompt}'''\n",
    "\n",
    "    prompt = f'''You are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n",
    "### Instruction:\n",
    "{system_prompt}\n",
    "\n",
    "{user_prompt}\n",
    "### Response:\n",
    "'''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_data(num_shots, eval_indices):\n",
    "    output = []\n",
    "\n",
    "    for i in tqdm(eval_indices):\n",
    "        test_problem = test_df.iloc[i]\n",
    "        train_problems = train_df.sample(n=num_shots, random_state=i)\n",
    "\n",
    "        line_with_context = {\n",
    "            \"input_index\": test_problem[\"task_id\"],\n",
    "            \"assigned_model\": \"deepseek-ai/deepseek-coder-6.7b-base\",\n",
    "            \"assigned_process\": 0,\n",
    "            \"filter_p\": 1,\n",
    "            \"context_string\": build_dsc_context_with_few_shot(test_problem, train_problems),\n",
    "            \"assigned_weight\": 2\n",
    "            # Note: I do not give gold answers here because I do not use it for evaluation.\n",
    "            # I could also always access it using task_id.\n",
    "        }\n",
    "\n",
    "        line_without_context = {\n",
    "            \"input_index\": test_problem[\"task_id\"],\n",
    "            \"assigned_model\": \"deepseek-ai/deepseek-coder-6.7b-base\",\n",
    "            \"assigned_process\": 1,\n",
    "            \"context_string\": build_dsc_context(test_problem),\n",
    "            \"assigned_weight\": -1\n",
    "        }\n",
    "\n",
    "        output.append(line_with_context)\n",
    "        output.append(line_without_context)\n",
    "\n",
    "    # turn to pandas dataframe\n",
    "    output_df = pd.DataFrame(output)\n",
    "    output_df.to_json(f\"/mnt/ebs/code/forked-context-aware-decoding/eval/apps/random_2_-1_{num_shots}shots_eval300.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 1823.35it/s]\n"
     ]
    }
   ],
   "source": [
    "num_shots = 1\n",
    "eval_indices = [912, 204, 2253, 2006, 1828, 1143, 839, 4467, 712, 4837, 3456, 260, 244, 767, 1791, 1905, 4139, 4931, 217, 4597, 1628, 4464, 3436, 1805, 3679, 4827, 2278, 53, 1307, 3462, 2787, 2276, 1273, 1763, 2757, 837, 759, 3112, 792, 2940, 2817, 4945, 2166, 355, 3763, 4392, 1022, 3100, 645, 4522, 2401, 2962, 4729, 1575, 569, 375, 1866, 2370, 653, 1907, 827, 3113, 2277, 3714, 2988, 1332, 3032, 2910, 1716, 2187, 584, 4990, 1401, 4375, 2005, 1338, 3786, 3108, 2211, 4562, 1799, 2656, 458, 1876, 262, 2584, 3286, 2193, 542, 1728, 4646, 2577, 1741, 4089, 3241, 3758, 1170, 2169, 2020, 4598, 4415, 2152, 4788, 3509, 4780, 3271, 2965, 1796, 1133, 4174, 4042, 744, 385, 898, 1252, 1310, 3458, 4885, 520, 3152, 3126, 4881, 3834, 4334, 2059, 4532, 94, 938, 4398, 2185, 2786, 913, 2404, 3561, 1295, 3716, 26, 2157, 4100, 1463, 4158, 871, 2444, 4988, 1629, 3063, 1323, 4418, 4344, 4, 4906, 2655, 4002, 159, 916, 2973, 2519, 1961, 474, 1973, 4647, 701, 3981, 566, 4363, 1030, 1051, 3893, 4503, 1352, 2171, 4322, 4969, 3466, 1735, 4417, 1647, 2553, 3268, 3059, 3588, 4239, 3698, 991, 2030, 1840, 524, 2769, 172, 4819, 4537, 1885, 4820, 1804, 58, 581, 482, 1875, 552, 257, 2706, 580, 4211, 1949, 2281, 3976, 1755, 1083, 4677, 4720, 3872, 1990, 3874, 3334, 1559, 772, 794, 3531, 2902, 3469, 3367, 3825, 443, 806, 496, 3298, 2779, 895, 2036, 1569, 1558, 4393, 3675, 1148, 1503, 3789, 2046, 617, 3630, 4508, 802, 414, 4428, 120, 764, 1936, 1362, 3329, 3978, 3943, 1751, 3285, 480, 1348, 3104, 17, 3198, 2172, 3727, 2336, 3465, 4552, 3986, 1268, 1555, 2430, 1783, 479, 4744, 4441, 499, 2569, 468, 410, 4785, 3905, 4119, 4350, 1289, 465, 4160, 656, 1522, 561, 4874, 556, 1926, 3307, 982, 4666, 2016, 4742, 4870, 325, 671, 3434, 4781, 4630, 4282, 2591]\n",
    "build_random_data(num_shots, eval_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_problems = train_df.sample(n=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>fn_name</th>\n",
       "      <th>input_sample</th>\n",
       "      <th>question</th>\n",
       "      <th>solutions</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>2764</td>\n",
       "      <td>find_abc_sumsqcube</td>\n",
       "      <td>[20, 8]</td>\n",
       "      <td>We are interested in collecting the triples of...</td>\n",
       "      <td>[from bisect import bisect_right as bisect\\n\\n...</td>\n",
       "      <td>introductory</td>\n",
       "      <td>https://www.codewars.com/kata/5618716a738b95ce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      task_id             fn_name input_sample  \\\n",
       "2764     2764  find_abc_sumsqcube      [20, 8]   \n",
       "\n",
       "                                               question  \\\n",
       "2764  We are interested in collecting the triples of...   \n",
       "\n",
       "                                              solutions    difficulty  \\\n",
       "2764  [from bisect import bisect_right as bisect\\n\\n...  introductory   \n",
       "\n",
       "                                                    url  \n",
       "2764  https://www.codewars.com/kata/5618716a738b95ce...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosa-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
